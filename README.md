# Objective Data Scientist !

A carefully designed plan for becoming a good Data Scientist with Python.

Data Science is a new and complex field. It appears as an extension of statistical modeling using programming and domain expertise.

*Data Scientist are better at statistics than any software engineer and better at software engineering than any statistician.*

Becoming a good data scientist requires a combination of education, skills, and experience. Here are some steps you can take to improve your chances of success in this field:

Get a strong foundation in mathematics and computer science: Data science involves working with large amounts of data, and a strong foundation in mathematics and computer science is essential for understanding and applying statistical and machine learning techniques.

Learn programming languages: Data scientists need to be proficient in at least one programming language, such as Python or R, in order to manipulate and analyze data. It is also helpful to have some knowledge of SQL for working with databases.

Acquire statistical and machine learning skills: Data science involves applying statistical and machine learning techniques to extract insights from data. It is important to have a good understanding of these techniques and be able to apply them effectively.

Gain experience: As with any field, experience is key to becoming a good data scientist. Consider taking on data science projects as part of your coursework or as a side project, and try to get internships or entry-level positions in the field to gain practical experience.

Stay up to date: Data science is a rapidly evolving field, and it is important to stay up to date with the latest technologies and techniques. Consider taking online courses or attending conferences to continue learning and staying current.


## Step 1. Mathematical & Computational Foundations

Choose one or more material from each topic and expect at least one year to learn these concepts and tools!


### Multivariable Calculus:

Multivariable calculus is a branch of calculus that deals with functions of multiple variables and extends the concepts of single-variable calculus. It allows for the analysis of functions and their behavior in higher-dimensional space.

The key concepts of multivariable calculus include partial derivatives, double integrals, and gradient vectors. Partial derivatives are used to describe how a function changes as one of its variables changes, while holding the other variables constant. Double integrals are used to calculate the area or volume of a region in higher-dimensional space. Gradient vectors, also known as "del" or "nabla" operators, are used to describe the direction of maximum increase of a function at a given point.

Multivariable calculus has numerous applications in fields such as physics, engineering, and economics. It is used to model and analyze systems with multiple interacting variables, and to optimize and make predictions about these systems.


[The Calculus of Functions of Several Variables](http://www.synechism.org/wp/the-calculus-of-functions-of-several-variables/)

[Multivariable & Vector Analysis](http://www.williamchen-mathematics.info/lnmvafolder/lnmva.html)

[Demonstrations of the fundamental concepts from multivariable calculus](https://github.com/Mason-McGough/MultivariableCalculus)

### Linear Algebra: the mathematics of matrices and data.

Linear algebra is a branch of mathematics that deals with linear equations and their representations in vector spaces. It is a fundamental mathematical toolkit for understanding systems of linear equations, as well as for studying advanced topics such as least squares methods, eigenvalues, and singular value decompositions.

The key concepts of linear algebra include vectors, matrices, and linear transformations. Vectors are objects that can be added and scaled (multiplied by a constant), and they can be used to represent points, directions, and other quantities in space. Matrices are rectangular arrays of numbers, and they can be used to represent systems of linear equations, as well as to perform linear transformations such as rotation and scaling. Linear transformations are functions that preserve the linear structure of a vector space, meaning that they map lines to lines and planes to planes.

Linear algebra has numerous applications in fields such as physics, engineering, computer science, and economics. It is used to model and analyze systems of linear equations, and to perform various mathematical operations such as solving systems of linear equations, finding eigenvalues and eigenvectors, and projecting vectors onto subspaces.



[Immersive Linear Algebra](http://immersivemath.com/ila/index.html)

[Matrix Methods in Data Analysis, Signal Processing, and Machine Learning](https://ocw.mit.edu/courses/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/)

[Introduction to Applied Linear Algebra â€“ Vectors, Matrices, and Least Squares](https://web.stanford.edu/~boyd/vmls/)

### Probability & Statistics:

Probability and statistics are two closely related fields of study that deal with the collection, analysis, interpretation, presentation, and organization of data. Probability is the study of random events and the likelihood of their occurrence, while statistics is the application of probability theory to the collection and analysis of data.

The key concepts of probability include random variables, probability distributions, and statistical independence. Random variables are quantities whose values are determined by the outcome of a random event. Probability distributions describe the possible values and likelihoods of a random variable. Statistical independence refers to the idea that the occurrence of one event does not affect the probability of another event occurring.

The key concepts of statistics include descriptive statistics, statistical estimation, and statistical inference. Descriptive statistics are techniques for organizing and summarizing data, such as calculating the mean, median, and standard deviation of a set of data. Statistical estimation is the process of using sample data to make inferences about a population. Statistical inference is the process of using statistical techniques to make predictions or decisions based on data.

Probability and statistics have numerous applications in fields such as economics, finance, biology, and computer science. They are used to analyze and interpret data, make predictions and decisions, and draw conclusions based on evidence.

[Introduction to Modern Statistics](https://www.openintro.org/book/ims/)

[Seeing Theory](https://seeing-theory.brown.edu/index.html#firstPage)

[Introduction to Probability for Data Science](https://probability4datascience.com/index.html)

[Introduction to Probability, Statistics, and Random Processes](https://www.probabilitycourse.com/)

### Mathematical Analysis:

Mathematical analysis is a branch of mathematics that deals with the study of limits and the properties of functions. It is a broad subject that includes many subfields such as calculus, differential equations, and real analysis.

The key concepts of mathematical analysis include limits, continuity, and differentiability. Limits are used to describe the behavior of a function as the input variable approaches a particular value. Continuity refers to the idea that a function does not have sudden breaks or jumps, but rather varies smoothly over its domain. Differentiability refers to the existence of a derivative of a function, which is a measure of how the function changes as the input variable changes.

Mathematical analysis has numerous applications in fields such as physics, engineering, and economics. It is used to model and analyze real-world phenomena using mathematical techniques, and to understand and describe the behavior of functions and systems. It is also a fundamental tool in the study of calculus and other areas of mathematics.

[Applied Analysis](https://www.math.ucdavis.edu/~hunter/book/pdfbook.html)

### Numerical Methods:

Numerical analysis is a branch of mathematics that deals with the design, analysis, and implementation of algorithms for solving problems involving continuous variables. It is a broad subject that includes many subfields such as numerical linear algebra, numerical optimization, and numerical differential equations.

The key concepts of numerical analysis include accuracy, stability, and efficiency. Accuracy refers to the degree to which the output of an algorithm approximates the true solution to a problem. Stability refers to the sensitivity of the output to small changes in the input. Efficiency refers to the computational cost of an algorithm, including the amount of time and memory required.

Numerical analysis has numerous applications in fields such as science, engineering, and finance. It is used to design and implement algorithms for solving problems involving continuous variables, such as those arising in scientific simulations, engineering design, and financial modeling. It is also used to analyze the behavior of algorithms and to understand the trade-offs between accuracy, stability, and efficiency.

[Holistic Numerical Methods](https://nm.mathforcollege.com/)

### Computational Thinking

### Computational Mathematics

### Computational Science

